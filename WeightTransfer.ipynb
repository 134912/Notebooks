{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WeightTransfer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zaidalyafeai/Notebooks/blob/master/WeightTransfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "fqNvA3-pePdn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## [@Zaid Alyafeai](https://twitter.com/zaidalyafeai)"
      ]
    },
    {
      "metadata": {
        "id": "tFZUCH-FS9PB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "In this tutorial we explain how to transfer weights from a static graph model built with TensorFlow to a dynamic graph built with Keras. We will first train a model using Tensorflow then we will create the same model in keras and transfer the trained weights between the two models. \n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/zaidalyafeai/Notebooks/master/images/weightrasnfer.png)"
      ]
    },
    {
      "metadata": {
        "id": "Bj4whuEqZhhs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "\n",
        "We will use [QuickDraw10](https://github.com/zaidalyafeai/QuickDraw10) which is a suggested alternative for mnist. QuickDraw10 constains 100K grayscale images with shapes (28 x 28)seperated into 80K for training and 20K for testing for labeling 10 classes. "
      ]
    },
    {
      "metadata": {
        "id": "DI3koqs9ayfc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download the Data"
      ]
    },
    {
      "metadata": {
        "id": "EEgAiZMAkYuI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "24a28b3a-6676-4499-a56a-5f56dfcd79b0"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/zaidalyafeai/QuickDraw10"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'QuickDraw10'...\n",
            "remote: Enumerating objects: 53, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 53 (delta 11), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "veRsNHa0av9T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load the Data"
      ]
    },
    {
      "metadata": {
        "id": "ICLDY1PpUtgO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "train_data = np.load('QuickDraw10/dataset/train-ubyte.npz')\n",
        "test_data  = np.load('QuickDraw10/dataset/test-ubyte.npz')\n",
        "\n",
        "x_train, y_train = train_data['a'], train_data['b']\n",
        "x_test,  y_test  = test_data['a'],  test_data['b']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QoV1CVXIc3J4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "N = x_train.shape[0]\n",
        "\n",
        "x_train = np.reshape(x_train/ 255., (x_train.shape[0], 28, 28, 1)).astype('float32')\n",
        "x_test = np.reshape(x_test/255., (x_test.shape[0], 28, 28, 1)).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iz6Bf5qPZyMl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TensorFlow Graph"
      ]
    },
    {
      "metadata": {
        "id": "wrDQ88OhSzvz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xKPhzFPVca2P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define the model inputs and outputs "
      ]
    },
    {
      "metadata": {
        "id": "74L6G12VcQP6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define the data\n",
        "with tf.name_scope(\"data\"):\n",
        "  X = tf.placeholder(tf.float32, shape = [None, 28, 28, 1], name = 'X')\n",
        "  y = tf.placeholder(tf.int32,   shape = [None], name = 'y')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "11Kpxof2cYgP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create the layers"
      ]
    },
    {
      "metadata": {
        "id": "4LPIoeRVU4-Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope(\"block1\"):\n",
        "  conv1 = tf.layers.conv2d(X, filters = 8, kernel_size = 3, \n",
        "                           activation = tf.nn.relu, padding = 'same', name = 'conv1')\n",
        "  pool1 = tf.layers.max_pooling2d(conv1, pool_size = 2, strides = 2, name = 'pool1')\n",
        "  \n",
        "with tf.name_scope(\"block2\"):\n",
        "  conv2 = tf.layers.conv2d(pool1, filters = 16, kernel_size = 3, \n",
        "                           activation = tf.nn.relu, padding = 'same', name = 'conv2')\n",
        "  pool2 = tf.layers.max_pooling2d(conv2, pool_size = 2, strides = 2, name = 'pool2')\n",
        "  \n",
        "with tf.name_scope(\"block3\"):\n",
        "  conv3 = tf.layers.conv2d(pool2, filters = 32, kernel_size = 3, \n",
        "                           activation = tf.nn.relu, padding = 'same', name = 'conv3')\n",
        "  pool3 = tf.layers.max_pooling2d(conv3, pool_size = 2, strides = 2, name = 'pool3')  \n",
        "  \n",
        "with tf.name_scope(\"flatten\"):\n",
        "  flatten = tf.reshape(pool3, shape = [-1, 3*3*32 ], name = 'flatten')\n",
        "  \n",
        "with tf.name_scope(\"dense\"):\n",
        "  logits = tf.layers.dense(flatten, units = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VodVRfNacdwG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define the training procedure and the evaluation metrics "
      ]
    },
    {
      "metadata": {
        "id": "G3VPMwTmfPca",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope(\"train\"):\n",
        "  #cross entropy loss\n",
        "  entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logits, labels = y)\n",
        "  loss = tf.reduce_mean(entropy)\n",
        "  \n",
        "  #minimize adam optimizer \n",
        "  optimizer = tf.train.AdamOptimizer()\n",
        "  backprob = optimizer.minimize(loss)\n",
        "  \n",
        "with tf.name_scope(\"eval\"):\n",
        "  #calculate the accuracy  \n",
        "  correct = tf.nn.in_top_k(logits,y,1)\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lnh3pC2phAeF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FoNWnCb-ez4F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "693774e8-d94e-4307-fce0-888c6bc7aa93"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "  epochs = 3\n",
        "  \n",
        "  #initialize all the variables \n",
        "  sess.run(init)\n",
        "  \n",
        "  #training \n",
        "  for epoch in range(0, epochs):\n",
        "    i = 0 \n",
        "    while i < N:\n",
        "      \n",
        "      #get the next batch \n",
        "      x_batch = x_train[i: i+BATCH_SIZE]\n",
        "      y_batch = y_train[i: i+BATCH_SIZE]\n",
        "            \n",
        "      #run the graph   \n",
        "      out = sess.run(backprob, feed_dict= {X:x_batch, y:y_batch})\n",
        "      i = i + BATCH_SIZE\n",
        "    print('------')  \n",
        "    acc_test  = accuracy.eval(feed_dict={X: x_test, y: y_test})\n",
        "    print(\"Epoch:\", epoch+1, \"test accuracy:\", acc_test)\n",
        "  \n",
        "  print('saving the weights ...')\n",
        "  #extract and save the weights \n",
        "  variables = [v for v in tf.trainable_variables()]\n",
        "  idx = 0\n",
        "  weights = []\n",
        "  for v in variables:\n",
        "      out = sess.run(v)\n",
        "      weights.append(out)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------\n",
            "Epoch: 1 test accuracy: 0.923\n",
            "------\n",
            "Epoch: 2 test accuracy: 0.9353\n",
            "------\n",
            "Epoch: 3 test accuracy: 0.93875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zn79ONlZLx-L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PE8rSI3cZ4qz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Keras Model"
      ]
    },
    {
      "metadata": {
        "id": "_Y4PTdLDL-WP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "96c60d30-8f92-4d60-ed55-003ee443ab39"
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Input, Convolution2D, MaxPooling2D, Flatten\n",
        "from keras.models import Sequential"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "wldUpaGaMnPh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Convolution2D(filters = 8, kernel_size = 3, activation = 'relu', padding = 'same' , input_shape = (28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
        "model.add(Convolution2D(filters = 16, kernel_size = 3, activation = 'relu', padding = 'same' , input_shape = (28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
        "model.add(Convolution2D(filters = 32, kernel_size = 3, activation = 'relu', padding = 'same' , input_shape = (28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units = 10))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AvasZolMZ-L_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load the Weights"
      ]
    },
    {
      "metadata": {
        "id": "32aIz3ZcQ7eO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "i = 0 \n",
        "for layer in model.layers:\n",
        "  #load the weights to the model layers\n",
        "  if 'conv2d' in layer.name or 'dense' in layer.name:\n",
        "    W = weights[i]\n",
        "    b = weights[i+1]\n",
        "    layer.set_weights([W, b])\n",
        "    i+=2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "niSyRsD0aDYj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ]
    },
    {
      "metadata": {
        "id": "7NYY9XlCOWSZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "26bbb625-7c1a-4d38-a8e4-65734b12fdf1"
      },
      "cell_type": "code",
      "source": [
        "n_values = np.max(y_test) + 1\n",
        "y_one_hot =  np.eye(n_values)[y_test]\n",
        "model.evaluate(x = x_test, y = y_one_hot)[1]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20000/20000 [==============================] - 2s 90us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.93875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "CiNJkR8crWzl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "https://www.kaggle.com/andrewrona22/an-example-of-cnn-using-tensorflow"
      ]
    }
  ]
}